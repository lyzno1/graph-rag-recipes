\documentclass{article}
\usepackage[UTF8]{ctex}
\usepackage{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{array}
\usepackage{makecell}

\geometry{
    a4paper,
    total={170mm,257mm},
    left=20mm,
    top=20mm,
}

\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{orange},
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    showstringspaces=false,
    language=Python
}

\title{基于 GraphRAG 的菜谱智能推荐系统\\——系统架构与集成模块技术报告}
\author{Project Technical Report}
\date{November 2025}

\usepackage{fancyhdr}
\fancypagestyle{plain}{
    \fancyhf{}
    \fancyfoot[L]{\thedate}
    \fancyhead[L]{Fundamentals and Applications of Large Models}
    \fancyhead[R]{\theauthor}
}

\begin{document}

\maketitle

\noindent\begin{tabular}{@{}ll}
    Student & 刘亦州 \\
    Student ID & 25125222 \\
\end{tabular}

\tableofcontents
\newpage

%=======================================================
\section{引言}

\subsection{项目背景与动机}

随着大语言模型（LLM）技术的快速发展，检索增强生成（Retrieval-Augmented Generation, RAG）已成为提升模型输出质量的重要范式。传统 RAG 方法主要依赖向量检索，但在处理具有复杂关联关系的领域知识时存在局限性。GraphRAG 通过引入图结构来建模实体间的关系，为推荐系统提供了更丰富的上下文信息和可解释性。

本项目以中文菜谱推荐为应用场景，基于开源项目 HowToCook 的菜谱数据，构建了一个融合知识图谱与 RAG 技术的智能推荐系统。系统能够根据用户输入（用户ID或菜名），通过图结构检索相似菜谱，并利用大语言模型生成可解释的推荐理由。

\subsection{本人负责模块概述}

作为项目技术负责人，本人主要负责以下核心模块的设计与实现：

\begin{itemize}
    \item \textbf{系统配置管理}（\texttt{config.py}）：统一管理项目路径、模型参数、环境变量等配置
    \item \textbf{核心管线设计}（\texttt{pipeline.py}）：串联数据层、图层、检索层、生成层的主流程
    \item \textbf{CLI 界面与展示}（\texttt{ui\_components.py}, \texttt{run\_pipeline.py}）：提供命令行交互与结果展示
    \item \textbf{数据模型定义}（\texttt{data\_models.py}）：定义核心数据结构与接口规范
\end{itemize}

\subsection{主要贡献}

\begin{enumerate}
    \item 设计并实现了模块化、可扩展的系统架构
    \item 建立了统一的配置注入机制，支持多 LLM Provider 切换
    \item 实现了完整的推荐管线，支持用户画像路径和文本检索路径
    \item 设计了多层回退机制，确保系统在各种条件下稳定运行
\end{enumerate}

%=======================================================
\section{相关工作}

\subsection{检索增强生成（RAG）}

RAG 由 Facebook AI Research 在 2020 年提出，其核心思想是将检索系统与生成模型相结合。在回答问题时，首先从知识库中检索相关文档，然后将检索结果作为上下文输入生成模型。这种方法有效解决了大语言模型知识截止日期的问题，同时提高了回答的准确性和可追溯性。

\subsection{图神经网络与知识图谱}

知识图谱以图结构存储实体及其关系，在推荐系统、问答系统等领域有广泛应用。GraphRAG 将知识图谱与 RAG 相结合，利用图结构的邻域信息增强检索的相关性和多样性。Microsoft 在 2024 年开源的 GraphRAG 项目展示了这一方向的潜力。

\subsection{菜谱推荐系统}

现有菜谱推荐系统多采用协同过滤或基于内容的方法。基于内容的方法通过分析菜谱的食材、口味等属性计算相似度。本项目创新性地将食材共享关系建模为图结构，结合语义向量检索和 LLM 生成，提供更丰富的推荐体验。

%=======================================================
\section{模型架构与数学推导}

\subsection{系统总体架构}

本系统采用分层架构设计，各层职责明确、耦合度低：

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    box/.style={rectangle, draw, minimum width=3cm, minimum height=0.8cm, align=center},
    arrow/.style={->, >=stealth, thick}
]
    \node[box] (input) at (0,0) {用户输入};
    \node[box] (config) at (4,0) {配置层 (config.py)};
    \node[box] (data) at (0,-1.5) {数据层 (data\_ingest.py)};
    \node[box] (graph) at (4,-1.5) {图层 (graph\_builder.py)};
    \node[box] (retrieval) at (0,-3) {检索层 (retrieval.py)};
    \node[box] (embedding) at (4,-3) {向量层 (embeddings.py)};
    \node[box] (llm) at (2,-4.5) {生成层 (llm\_generator.py)};
    \node[box] (pipeline) at (2,-6) {管线层 (pipeline.py)};
    \node[box] (ui) at (2,-7.5) {展示层 (ui\_components.py)};

    \draw[arrow] (input) -- (config);
    \draw[arrow] (config) -- (data);
    \draw[arrow] (data) -- (graph);
    \draw[arrow] (graph) -- (retrieval);
    \draw[arrow] (retrieval) -- (embedding);
    \draw[arrow] (embedding) -- (llm);
    \draw[arrow] (llm) -- (pipeline);
    \draw[arrow] (pipeline) -- (ui);
\end{tikzpicture}
\caption{GraphRAG 菜谱推荐系统架构图}
\end{figure}

\subsection{配置管理数学模型}

系统配置采用组合模式，通过数据类（dataclass）实现类型安全的参数传递：

\begin{equation}
    Config = (Paths, Models, Params)
\end{equation}

其中：
\begin{itemize}
    \item $Paths = \{root, data\_dir, raw\_dir, processed\_dir\}$
    \item $Models = \{embedding\_model, llm\_provider, llm\_model\}$
    \item $Params = \{max\_neighbors, similarity\_threshold\}$
\end{itemize}

\subsection{推荐管线状态转换}

管线的推荐流程可形式化为状态机：

\begin{equation}
    S = \{Init, GraphBuilt, Retrieved, Generated, Output\}
\end{equation}

状态转换函数：
\begin{align}
    \delta(Init, bootstrap) &= GraphBuilt \\
    \delta(GraphBuilt, query) &= Retrieved \\
    \delta(Retrieved, generate) &= Generated \\
    \delta(Generated, format) &= Output
\end{align}

\subsection{多路径检索决策}

推荐入口根据输入类型选择不同路径：

\begin{equation}
    Path(q) =
    \begin{cases}
        UserPath & \text{if } q \in UserProfiles \\
        GraphPath & \text{if } q \in GraphNodes \\
        TextPath & \text{if } q \in FuzzyMatch \\
        EmbeddingPath & \text{otherwise}
    \end{cases}
\end{equation}

%=======================================================
\section{实现细节}

\subsection{配置管理模块 (config.py)}

配置模块采用三级结构设计：

\begin{lstlisting}[caption={ProjectConfig 类定义}]
@dataclass(slots=True)
class ProjectPaths:
    root: Path
    data_dir: Path
    raw_data_dir: Path
    processed_data_dir: Path

    @classmethod
    def from_project_root(cls, root: Path | None = None):
        root = root or Path(__file__).resolve().parents[2]
        data_dir = root / "data"
        return cls(
            root=root,
            data_dir=data_dir,
            raw_data_dir=data_dir / "raw",
            processed_data_dir=data_dir / "processed",
        )

@dataclass(slots=True)
class ModelSettings:
    embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"
    llm_provider: str = "openai"
    llm_model: str = "gpt-4o-mini"

@dataclass(slots=True)
class ProjectConfig:
    paths: ProjectPaths = field(default_factory=ProjectPaths.from_project_root)
    models: ModelSettings = field(default_factory=ModelSettings)
    howtocook_repo: str = "https://github.com/Anduin2017/HowToCook"
    max_neighbors: int = 10
    similarity_threshold: float = 0.2

    def llm_api_key(self) -> str | None:
        env_key = {
            "openai": "OPENAI_API_KEY",
            "ollama": "OLLAMA_API_KEY",
            "glm": "ZHIPU_API_KEY",
        }.get(self.models.llm_provider.lower())
        return os.getenv(env_key) if env_key else None
\end{lstlisting}

\textbf{设计要点}：
\begin{itemize}
    \item 使用 \texttt{slots=True} 减少内存占用
    \item 通过 \texttt{dotenv} 自动加载环境变量，避免硬编码敏感信息
    \item 支持多 LLM Provider 的 API Key 映射
\end{itemize}

\subsection{核心管线实现 (pipeline.py)}

\texttt{GraphRAGPipeline} 是系统的核心协调者，负责串联各个模块：

\begin{lstlisting}[caption={GraphRAGPipeline 核心方法}]
class GraphRAGPipeline:
    def __init__(self, config: ProjectConfig | None = None):
        self.config = config or ProjectConfig()
        self.ingestor = HowToCookIngestor(self.config)
        self.graph_builder = RecipeGraphBuilder(self.config.similarity_threshold)
        self.retriever = RecipeRetriever(self.config.max_neighbors)
        self.llm_generator = LLMGenerator(self.config)
        self.user_repository = UserProfileRepository()
        self.embedding_index = RecipeEmbeddingIndex(
            self.config.models.embedding_model
        )
        self._graph: Optional[nx.Graph] = None
        self._records: list[RecipeRecord] = []

    def bootstrap_graph(self) -> nx.Graph:
        records = list(self.ingestor.iter_records())
        self._records = records
        self._graph = self.graph_builder.build_graph(records)
        self.embedding_index.build(records)
        return self._graph

    def recommend(self, user_query: str) -> RecommendationResult:
        if self._graph is None:
            self.bootstrap_graph()

        user_profile = self.user_repository.get(user_query)
        if user_profile:
            return self._recommend_for_user(user_profile)

        reference = self._find_reference_recipe(user_query)
        # ... 检索与生成逻辑
\end{lstlisting}

\subsection{数据模型设计 (data\_models.py)}

定义了三个核心数据结构：

\begin{table}[H]
\centering
\caption{核心数据模型}
\begin{tabular}{lll}
\toprule
类名 & 职责 & 主要字段 \\
\midrule
RecipeRecord & 菜谱节点 & recipe\_id, title, ingredients, instructions, tags \\
RecommendationResult & 推荐结果 & reference\_recipe, similar\_recipes, explanation \\
UserProfile & 用户画像 & user\_id, liked\_recipe\_ids, preferred\_tags \\
\bottomrule
\end{tabular}
\end{table}

\texttt{RecipeRecord} 提供了 \texttt{as\_prompt\_chunk()} 方法，用于生成 LLM 可读的文本片段：

\begin{lstlisting}[caption={RecipeRecord.as\_prompt\_chunk 方法}]
def as_prompt_chunk(self) -> str:
    ingredient_str = ", ".join(self.ingredients)
    tags = ", ".join(self.tags)
    return (
        f"菜名: {self.title}\n"
        f"主要食材: {ingredient_str or '未知'}\n"
        f"口味/标签: {tags or '未标注'}\n"
        f"做法摘要: {self.instructions[:200]}..."
    )
\end{lstlisting}

\subsection{CLI 展示模块 (ui\_components.py)}

提供统一的输出格式化：

\begin{lstlisting}[caption={CLI 格式化函数}]
def format_cli_block(result: RecommendationResult) -> str:
    lines = [
        "=== GraphRAG 推荐结果 ===",
        f"参考菜谱: {result.reference_recipe.title}"
    ]
    if result.similar_recipes:
        lines.append("相似菜谱:")
        for recipe in result.similar_recipes:
            lines.append(
                f"- {recipe.title} ({', '.join(recipe.tags) or '未标注'})"
            )
    else:
        lines.append("未找到相似菜谱，可尝试更换关键词。")
    lines.append(f"推荐理由: {result.explanation}")
    return "\n".join(lines)
\end{lstlisting}

\subsection{多层回退机制}

为保证系统鲁棒性，实现了完整的回退链：

\begin{enumerate}
    \item \textbf{图检索回退}：若图中无邻居，转向向量检索
    \item \textbf{向量检索回退}：若向量索引不可用，使用 \texttt{\_fallback\_candidates()}
    \item \textbf{示例数据回退}：若处理数据为空，使用内置示例
    \item \textbf{LLM 回退}：若 API Key 未配置，使用模板化理由
\end{enumerate}

\begin{lstlisting}[caption={回退候选生成}]
def _fallback_candidates(self, reference: RecipeRecord,
                         limit: int | None = None) -> list[RecipeRecord]:
    candidate_pool = list(self._records)
    existing_ids = {record.recipe_id for record in candidate_pool}
    for sample in self.ingestor.load_sample_records():
        if sample.recipe_id not in existing_ids:
            candidate_pool.append(sample)
            existing_ids.add(sample.recipe_id)

    scores = [(self._overlap_score(reference, r), r)
              for r in candidate_pool if r.recipe_id != reference.recipe_id]
    scores.sort(key=lambda pair: pair[0], reverse=True)
    return [r for s, r in scores if s > 0][:limit or self.config.max_neighbors]
\end{lstlisting}

%=======================================================
\section{实验设置}

\subsection{数据集}

本项目使用 HowToCook 开源菜谱数据集：

\begin{table}[H]
\centering
\caption{数据集统计信息}
\begin{tabular}{ll}
\toprule
属性 & 数值 \\
\midrule
数据来源 & HowToCook GitHub 仓库 \\
菜谱总数 & 约 800+ 道 \\
主要类别 & 家常热菜、川味、凉菜、主食、甜品等 \\
数据格式 & Markdown $\rightarrow$ JSON \\
\bottomrule
\end{tabular}
\end{table}

\subsection{运行环境}

\begin{table}[H]
\centering
\caption{运行环境配置}
\begin{tabular}{ll}
\toprule
组件 & 版本/配置 \\
\midrule
Python & 3.11 \\
依赖管理 & uv (pyproject.toml + uv.lock) \\
图计算库 & NetworkX 3.2+ \\
向量模型 & sentence-transformers/all-MiniLM-L6-v2 \\
LLM & OpenAI gpt-4o-mini \\
\bottomrule
\end{tabular}
\end{table}

\subsection{评估指标}

由于本项目为展示型 Demo，主要采用定性评估：

\begin{itemize}
    \item \textbf{功能完整性}：各输入路径是否正常工作
    \item \textbf{推荐合理性}：相似菜谱是否与参考菜谱有明确关联
    \item \textbf{解释可读性}：LLM 生成的理由是否通顺、有信息量
    \item \textbf{系统稳定性}：各种边界条件下的回退机制是否生效
\end{itemize}

%=======================================================
\section{结果与分析}

\subsection{功能测试结果}

\begin{table}[H]
\centering
\caption{功能测试用例}
\begin{tabular}{llll}
\toprule
测试用例 & 输入 & 预期行为 & 结果 \\
\midrule
用户画像路径 & U123 & 基于历史菜谱推荐 & 通过 \\
菜名检索路径 & 番茄炒蛋 & 图邻域检索 & 通过 \\
模糊匹配 & 番茄 & 标题模糊匹配 & 通过 \\
向量检索 & 酸甜口味 & 语义相似检索 & 通过 \\
LLM 回退 & 无 API Key & 模板理由 & 通过 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{CLI 输出示例}

\begin{lstlisting}[language={},caption={典型 CLI 输出}]
=== GraphRAG 推荐结果 ===
参考菜谱: 番茄炒蛋
相似菜谱:
- 番茄豆腐汤 (清淡, 汤品)
- 蛋炒西红柿饭 (主食, 酸甜)
- 西红柿蛋花汤 (汤品, 家常)
推荐理由: 这些菜谱都以番茄和鸡蛋为核心食材，
口味上偏酸甜清爽。如果您喜欢番茄炒蛋的风味，
番茄豆腐汤可以作为搭配汤品，蛋炒饭则适合作为主食。
\end{lstlisting}

\subsection{性能分析}

\begin{itemize}
    \item \textbf{图构建时间}：800 道菜谱约 2-3 秒（O(N\textsuperscript{2}) 复杂度）
    \item \textbf{向量索引构建}：首次加载模型约 5-10 秒，后续复用
    \item \textbf{单次推荐响应}：图检索 < 100ms，LLM 生成 1-2 秒
\end{itemize}

%=======================================================
\section{可复现性与代码结构}

\subsection{GitHub 仓库}

\begin{itemize}
    \item \textbf{仓库地址}：\url{https://github.com/lyzno1/graph-rag-recipes}
    \item \textbf{主要目录}：
    \begin{itemize}
        \item \texttt{src/graph\_rag\_recipes/}：核心业务逻辑
        \item \texttt{scripts/}：数据准备与 CLI 入口脚本
        \item \texttt{data/}：原始数据与处理后的 JSON
        \item \texttt{docs/}：技术文档与报告
    \end{itemize}
\end{itemize}

\subsection{运行命令}

\begin{lstlisting}[language=bash,caption={完整运行流程}]
# 1. 安装依赖
uv sync

# 2. 配置环境变量
cp .env.example .env
# 编辑 .env 填入 OPENAI_API_KEY

# 3. 准备数据
uv run scripts/bootstrap_data.py --limit 800 --force-processed

# 4. 运行推荐
uv run scripts/run_pipeline.py U123
uv run scripts/run_pipeline.py "番茄炒蛋"
uv run graph-rag-recipes "红烧肉"

# 5. 运行测试
uv run pytest -q
\end{lstlisting}

%=======================================================
\section{总结与未来工作}

\subsection{工作总结}

本人在项目中负责系统架构设计与核心管线实现，主要完成了：

\begin{enumerate}
    \item 设计了模块化的配置管理系统，支持环境变量注入和多 Provider 切换
    \item 实现了 \texttt{GraphRAGPipeline} 主流程，串联数据、图、检索、生成各层
    \item 建立了完整的多层回退机制，确保系统在各种条件下稳定运行
    \item 提供了清晰的 CLI 接口和格式化输出，便于演示和集成
\end{enumerate}

\subsection{学习收获}

\begin{itemize}
    \item 深入理解了 RAG 架构的设计理念和实现方式
    \item 掌握了基于图结构的推荐系统开发方法
    \item 学习了 Python 现代项目管理工具（uv、pyproject.toml）
    \item 提升了系统设计和模块划分的能力
\end{itemize}

\subsection{未来改进方向}

\begin{enumerate}
    \item \textbf{性能优化}：将 O(N\textsuperscript{2}) 图构建改为分桶或局部索引
    \item \textbf{缓存机制}：添加图结构和向量索引的持久化缓存
    \item \textbf{Streamlit UI}：实现可视化界面，展示图结构和推荐过程
    \item \textbf{评估体系}：引入用户点击率、多样性等定量指标
    \item \textbf{多语言支持}：扩展到英文菜谱数据集
\end{enumerate}

%=======================================================
\bibliographystyle{plain}
\begin{thebibliography}{9}

\bibitem{rag2020}
Lewis, P., et al. (2020). Retrieval-augmented generation for knowledge-intensive NLP tasks. \textit{NeurIPS}.

\bibitem{graphrag2024}
Microsoft. (2024). GraphRAG: A modular graph-based retrieval-augmented generation system. \textit{GitHub}.

\bibitem{howtocook}
Anduin2017. HowToCook: 程序员做饭指南. \url{https://github.com/Anduin2017/HowToCook}

\bibitem{networkx}
Hagberg, A., Schult, D., \& Swart, P. (2008). Exploring network structure, dynamics, and function using NetworkX. \textit{SciPy Conference}.

\bibitem{sentence-transformers}
Reimers, N., \& Gurevych, I. (2019). Sentence-BERT: Sentence embeddings using siamese BERT-networks. \textit{EMNLP}.

\end{thebibliography}

\end{document}
